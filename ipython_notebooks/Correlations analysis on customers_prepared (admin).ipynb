{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.5"
    },
    "analyzedDataset": "customers_prepared",
    "creator": "admin",
    "hide_input": false,
    "modifiedBy": "yathin.gn"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analyzing correlations betweeen variables in customers"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pylab inline\nimport dataiku                          # Access to Dataiku datasets\nimport pandas as pd, numpy as np        # Data manipulation \nimport scipy.cluster.hierarchy as sch   # Used for reordering the correlation matrix\nimport seaborn as sns                   # Graphing\nsns.set(style\u003d\"white\")                  # Tuning the style of charts\nimport warnings                         # Disable some warnings\nwarnings.filterwarnings(\"ignore\",category\u003dDeprecationWarning)\n\n# Take a handle on the dataset\nmydataset \u003d dataiku.Dataset(\"customers_prepared\")\n\n# Load the first 100\u0027000 lines.\n# You can also load random samples, limit yourself to some columns, or only load\n# data matching some filters.\n#\n# Please refer to the Dataiku Python API documentation for more information\ndf \u003d mydataset.get_dataframe(\n    limit \u003d 100000)\n\n# Get the column names\nnumerical_columns \u003d list(df.select_dtypes(include\u003d[np.number]).columns)\ncategorical_columns \u003d list(df.select_dtypes(include\u003d[object]).columns)\ndate_columns \u003d list(df.select_dtypes(include\u003d[\u0027\u003cM8[ns]\u0027]).columns)\n\n\n# Select variables to plot for the correlation matrix\ncorr_matrix_vars \u003d numerical_columns[0:50]\n\n\n# Only select the requested columns\ndf_corr_matrix \u003d df[corr_matrix_vars]\n\n# This computes the Pearson coefficient for all couples\ncorr \u003d df_corr_matrix.corr().fillna(0)\n\n# Start drawing\n\n# Generate a mask for the upper triangle\nmask \u003d np.zeros_like(corr, dtype\u003dnp.bool)\nmask[np.triu_indices_from(mask)] \u003d True\n\n# Set up the matplotlib figure\nsize \u003d max(10, len(corr.columns)/2.)\nf, ax \u003d plt.subplots(figsize\u003d(size, size))\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask\u003dmask, square\u003dTrue, linewidths\u003d.5, cbar_kws\u003d{\"shrink\": 0.5}, ax\u003dax)\n\n# Generate features and distance matrix.\nD \u003d corr.values\n# Compute and plot dendrogram.\nY \u003d sch.linkage(D, method\u003d\u0027centroid\u0027)\nZ \u003d sch.dendrogram(Y, orientation\u003d\u0027right\u0027,no_plot\u003dTrue)\n# Compute distance matrix.\nindex \u003d Z[\u0027leaves\u0027]\nD \u003d D[index,:]\nD \u003d D[:,index]\n\n# Generate a mask for the upper triangle\nmask \u003d np.zeros_like(corr, dtype\u003dnp.bool)\nmask[np.triu_indices_from(mask)] \u003d True\n\n# Set up the matplotlib figure\nsize \u003d max(10, len(corr.columns)/2.)\nf, ax \u003d plt.subplots(figsize\u003d(size, size))\n\n# Draw the heatmap with the mask and correct aspect ratio\n\nsns.heatmap(D, mask\u003dmask, square\u003dTrue, linewidths\u003d.5, cbar_kws\u003d{\"shrink\": 0.5}, ax\u003dax)\n#ax.set(xticks\u003drange(len(corr.columns)), xticklabels\u003dcorr.columns[index], yticks\u003drange(len(corr.columns)), yticklabels\u003dreversed(corr.columns[index]))\nax.set_xticklabels(corr.columns[index], rotation\u003d90, ha\u003d\u0027center\u0027);\nax.set_yticklabels(reversed(corr.columns[index]), rotation\u003d0);"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.pairplot"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Only generate the scatterplot matrix on a sample\ndf_scatter_samp \u003d df.sample(min(5000, df.shape[0])) # 5000 points maximum on the scatter plot\n\n# Take the first 4 numerical variables to plot the scatterplot matrix\nscatter_matrix_vars \u003d numerical_columns[0:4]\n\n# If we have categorical variables, use the categorical variables with the lowest number of modalities\n# to plot the points of the scatterplot\nscatter_matrix_color \u003d None\n\ncat_cols_with_cards \u003d [(x, df[x].nunique()) for x in categorical_columns]\n# We don\u0027t want to take a column with only a single modality\n# and also we don\u0027t want variables with more than 10 modalities (would not really make sense to plot)\ncat_cols_with_cards_f \u003d [x for x in cat_cols_with_cards if x[1] \u003e\u003d 2 and x[1] \u003c\u003d 10]\n\nif len(cat_cols_with_cards_f) \u003e 0:\n    # We have at least one categorical variable with a good number of modalities, use it\n    scatter_matrix_color \u003d sorted(cat_cols_with_cards_f, key\u003d lambda c : c[1])[0][0]\n\nscatter_matrix_color \u003d \u0027Churn\u0027\n\n# Seaborn (the graphic library) doesn\u0027t like NaNs, so fill the matrix\ndf_filled \u003d df.fillna(0)\nsns.pairplot(df_filled, vars \u003d scatter_matrix_vars, hue_order\u003d[1,0], hue\u003dscatter_matrix_color, palette\u003d\"husl\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## See the relation between two features, including categorical features \u003ca id\u003d\"two-vars\" /\u003e"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute cardinalities of our categorical variables\ncat_cols_with_cards \u003d [(x, df[x].nunique()) for x in categorical_columns]\n\n# For proper display, we only want columns with modalities between 2 and 10\ncat_cols_with_cards_f \u003d [x for x in cat_cols_with_cards if x[1] \u003e\u003d 2 and x[1] \u003c\u003d 10]\n\nnb_suitable_cats \u003d len(cat_cols_with_cards_f)\nnb_num \u003d len(numerical_columns)\n\nif nb_suitable_cats \u003e\u003d 1 and nb_num \u003e\u003d 1:\n    tf_feat1 \u003d cat_cols_with_cards_f[0][0]\n    tf_feat2 \u003d numerical_columns[0]\n\nelif nb_suitable_cats \u003d\u003d 0 and nb_num \u003e\u003d 2:\n    tf_feat1 \u003d numerical_columns[0]\n    tf_feat2 \u003d numerical_columns[1]\n\nelse:\n    raise ValueError(\"Failed to automatically select proper variables to plot, please select manually\")\n\n\n\n\nif tf_feat1 in numerical_columns and tf_feat2 in numerical_columns:\n    sns.pairplot(df[[tf_feat1, tf_feat2]])\n    \nif tf_feat1 in numerical_columns and tf_feat2 in categorical_columns:\n    sns.FacetGrid(df, col\u003dtf_feat2, col_wrap\u003d5, hue\u003dNone).map(sns.distplot, tf_feat1)\n    \nif tf_feat1 in categorical_columns and tf_feat2 in numerical_columns:\n    sns.FacetGrid(df, col\u003dtf_feat1, col_wrap\u003d5, hue\u003dNone).map(sns.distplot, tf_feat2)\n    \nif tf_feat1 in categorical_columns and tf_feat2 in categorical_columns:\n    tf_list \u003d [tf_feat1, tf_feat2]\n    tf_unique_count \u003d [df[feat].unique().__len__() for feat in tf_list]\n    tf_min_loc \u003d tf_unique_count.index(min(tf_unique_count))\n    sns.FacetGrid(data\u003ddf, col\u003dtf_list[tf_min_loc], col_wrap\u003d5, hue\u003dNone).map(sns.countplot, tf_list[(tf_min_loc+1)%2], order\u003ddf[tf_list[(tf_min_loc+1)%2]].unique())"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}